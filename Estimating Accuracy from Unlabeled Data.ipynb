{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Accuracy from Unlabeled Data\n",
    "\n",
    "Try to implement the Bayesian Error Estimation (BEE) model in following paper. This is based on my limited understanding and I can't guarantee the implementation is bug-free.\n",
    "\n",
    "[Emmanouil Antonios Platanios, Avinava Dubey, Tom Mitchell ; Proceedings of The 33rd International Conference on Machine Learning, PMLR 48:1416-1425, 2016.](http://proceedings.mlr.press/v48/platanios16.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Generate dummy data\n",
    "\n",
    "In real-life, the estimations should come from estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 50\n",
    "num_estimators = 4\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_matrix = np.random.randint(0, 2, (num_samples, num_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gibbs Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = labeling_matrix.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial error rate: [0.11223538 0.09043202 0.10214499 0.07726982]\n"
     ]
    }
   ],
   "source": [
    "true_labels = np.random.randint(0, 2, num_samples)\n",
    "error_rates = 0.2*np.random.random(num_estimators)\n",
    "print(\"initial error rate:\", error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyper-parameters > 1 so that it's convex shape with mean 0.5. \n",
    "alpha_p, beta_p, alpha_e, beta_e = 2, 2, 2, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_p():\n",
    "    \"\"\" equation 2 + discounting the old label when sampling\n",
    "    \"\"\"\n",
    "    sigma_l = np.sum(true_labels)\n",
    "    return np.random.beta(alpha_p + sigma_l, beta_p + num_samples - sigma_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_l(p, i):\n",
    "    \"\"\" equation 3\n",
    "    \"\"\"\n",
    "    pi = 1\n",
    "    # the number of correct predictions of each estimator. dim [num_estimators, 1]\n",
    "    pi = np.zeros(2)  # the pi value for l=0 and l=1\n",
    "    for k in range(2):    \n",
    "        num_corrects = labeling_matrix[i,:] == k\n",
    "        temp = np.power(error_rates, 1 - num_corrects)*np.power(1 - error_rates, num_corrects)\n",
    "        pi[k] = np.prod(temp)\n",
    "    prob = pi * np.asarray([1-p, p])\n",
    "    positive_prob = prob[1]/np.sum(prob)\n",
    "    return random.binomial(1, positive_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_e(j):\n",
    "    \"\"\" equation 4\n",
    "    \"\"\"\n",
    "    sigma_j = np.sum(labeling_matrix[:, j] == true_labels)\n",
    "    return np.random.beta(alpha_e + sigma_j, beta_e + num_samples - sigma_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 :\n",
      "Accuracy [0.1113605  0.14529091 0.29715096 0.14500209]\n",
      "Iteration 1 :\n",
      "Accuracy [0.96665613 0.93794597 0.68095726 0.97851989]\n",
      "Iteration 2 :\n",
      "Accuracy [0.09558476 0.08943538 0.31542269 0.06481639]\n",
      "Iteration 3 :\n",
      "Accuracy [0.93316706 0.92556004 0.6528714  0.96728755]\n",
      "Iteration 4 :\n",
      "Accuracy [0.09743072 0.08342346 0.4194996  0.10258508]\n",
      "Iteration 5 :\n",
      "Accuracy [0.93246761 0.92822207 0.705937   0.95412881]\n",
      "Iteration 6 :\n",
      "Accuracy [0.0693895  0.1451995  0.41912669 0.04520672]\n",
      "Iteration 7 :\n",
      "Accuracy [0.9629295  0.91559994 0.68213596 0.97005163]\n",
      "Iteration 8 :\n",
      "Accuracy [0.0805446  0.10719331 0.39014003 0.08738436]\n",
      "Iteration 9 :\n",
      "Accuracy [0.94776536 0.93314799 0.68136139 0.93279774]\n",
      "Iteration 10 :\n",
      "Accuracy [0.07772267 0.09775339 0.32426243 0.09794675]\n",
      "Iteration 11 :\n",
      "Accuracy [0.94670279 0.94160717 0.65472558 0.97841544]\n",
      "Iteration 12 :\n",
      "Accuracy [0.09030817 0.10477313 0.36965285 0.04090852]\n",
      "Iteration 13 :\n",
      "Accuracy [0.95820329 0.93890483 0.64415449 0.97212839]\n",
      "Iteration 14 :\n",
      "Accuracy [0.04997676 0.10402377 0.3961222  0.05295794]\n",
      "Iteration 15 :\n",
      "Accuracy [0.93277256 0.90353864 0.66578352 0.97940311]\n",
      "Iteration 16 :\n",
      "Accuracy [0.10314439 0.13492018 0.37946514 0.0514847 ]\n",
      "Iteration 17 :\n",
      "Accuracy [0.97293525 0.91145099 0.64964004 0.97128416]\n",
      "Iteration 18 :\n",
      "Accuracy [0.07249753 0.13821812 0.31221359 0.06096085]\n",
      "Iteration 19 :\n",
      "Accuracy [0.98738916 0.93249638 0.66262219 0.97825298]\n",
      "Iteration 20 :\n",
      "Accuracy [0.05269069 0.14153216 0.35614607 0.09267648]\n",
      "Iteration 21 :\n",
      "Accuracy [0.98050518 0.91218336 0.64370362 0.98027954]\n",
      "Iteration 22 :\n",
      "Accuracy [0.04955426 0.10785134 0.38930897 0.08970477]\n",
      "Iteration 23 :\n",
      "Accuracy [0.97089323 0.90424449 0.69031676 0.96041907]\n",
      "Iteration 24 :\n",
      "Accuracy [0.06908711 0.12077083 0.29211217 0.03744912]\n",
      "Iteration 25 :\n",
      "Accuracy [0.96182191 0.95321311 0.6926833  0.96295441]\n",
      "Iteration 26 :\n",
      "Accuracy [0.10637621 0.07959566 0.38349066 0.10013215]\n",
      "Iteration 27 :\n",
      "Accuracy [0.92656111 0.94113384 0.64227607 0.9717758 ]\n",
      "Iteration 28 :\n",
      "Accuracy [0.11214817 0.10828446 0.40272626 0.06528159]\n",
      "Iteration 29 :\n",
      "Accuracy [0.96263754 0.92019194 0.67214998 0.9760032 ]\n",
      "Iteration 30 :\n",
      "Accuracy [0.12476133 0.11953023 0.36097771 0.04948533]\n",
      "Iteration 31 :\n",
      "Accuracy [0.97826441 0.90271262 0.66419368 0.96433158]\n",
      "Iteration 32 :\n",
      "Accuracy [0.10406455 0.08889633 0.38005892 0.08166526]\n",
      "Iteration 33 :\n",
      "Accuracy [0.94384077 0.93962214 0.65685519 0.97918115]\n",
      "Iteration 34 :\n",
      "Accuracy [0.11418127 0.10453497 0.37994766 0.0646803 ]\n",
      "Iteration 35 :\n",
      "Accuracy [0.95893835 0.93425194 0.68977387 0.95071542]\n",
      "Iteration 36 :\n",
      "Accuracy [0.06541539 0.13436041 0.3534414  0.06012497]\n",
      "Iteration 37 :\n",
      "Accuracy [0.97125427 0.95550269 0.80114912 0.97579089]\n",
      "Iteration 38 :\n",
      "Accuracy [0.10030429 0.06467741 0.32597779 0.03980273]\n",
      "Iteration 39 :\n",
      "Accuracy [0.95163346 0.91922414 0.69376378 0.9349583 ]\n",
      "Iteration 40 :\n",
      "Accuracy [0.14675598 0.09084923 0.36782356 0.07828906]\n",
      "Iteration 41 :\n",
      "Accuracy [0.93348445 0.95256497 0.69981507 0.92781471]\n",
      "Iteration 42 :\n",
      "Accuracy [0.10389009 0.11585683 0.34257041 0.09238075]\n",
      "Iteration 43 :\n",
      "Accuracy [0.94284102 0.88891573 0.68919411 0.94310755]\n",
      "Iteration 44 :\n",
      "Accuracy [0.09319777 0.13351746 0.36498552 0.10434916]\n",
      "Iteration 45 :\n",
      "Accuracy [0.92692612 0.92806992 0.71189047 0.96258496]\n",
      "Iteration 46 :\n",
      "Accuracy [0.10571721 0.12604868 0.32891434 0.07496766]\n",
      "Iteration 47 :\n",
      "Accuracy [0.93518638 0.91998285 0.60578014 0.95926724]\n",
      "Iteration 48 :\n",
      "Accuracy [0.05140807 0.09771652 0.40114502 0.1117691 ]\n",
      "Iteration 49 :\n",
      "Accuracy [0.95191847 0.91160164 0.64867393 0.95434365]\n"
     ]
    }
   ],
   "source": [
    "for it in range(num_iters):\n",
    "    for i in range(num_samples):\n",
    "        p = sample_p()\n",
    "        true_labels[i] = sample_l(p, i)\n",
    "    for j in range(num_estimators):\n",
    "        error_rates[j] = sample_e(j)\n",
    "    print(\"Iteration\", it, \":\")\n",
    "    print(\"Accuracy\", 1 - error_rates)\n",
    "    #print(true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate some real predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33, random_state=42)\n",
    "num_samples = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative 1: varying the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples: (6, 30)\n",
      "0.9414893617021277\n",
      "num_samples: (9, 30)\n",
      "0.9361702127659575\n",
      "num_samples: (22, 30)\n",
      "0.9148936170212766\n",
      "num_samples: (35, 30)\n",
      "0.9574468085106383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "train_ratios = [0.02, 0.02, 0.05, 0.1]\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(train_ratios)):\n",
    "    mask = np.random.binomial(1, train_ratios[i], num_samples)\n",
    "    #print(mask)\n",
    "    X = X_train[mask==1]\n",
    "    y = y_train[mask==1]\n",
    "    print(\"num_samples:\", X.shape)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    print(model.score(X_test, y_test))\n",
    "    predictions.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative 2: split the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples: (381, 2)\n",
      "0.9148936170212766\n",
      "num_samples: (381, 13)\n",
      "0.9202127659574468\n",
      "num_samples: (381, 2)\n",
      "0.6436170212765957\n",
      "num_samples: (381, 13)\n",
      "0.9680851063829787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "feature_ids = [0, 2, 15, 17, 30]\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(train_ratios)):\n",
    "    X = X_train[:, feature_ids[i]: feature_ids[i+1]]\n",
    "    y = y_train\n",
    "    X_test_temp = X_test[:, feature_ids[i]: feature_ids[i+1]]\n",
    "    print(\"num_samples:\", X.shape)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    print(model.score(X_test_temp, y_test))\n",
    "    predictions.append(model.predict(X_test_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 4)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.column_stack(predictions)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_matrix = predictions \n",
    "# set the variable down. Now go back to section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
