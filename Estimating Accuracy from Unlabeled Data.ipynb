{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Accuracy from Unlabeled Data\n",
    "\n",
    "Try to implement the Bayesian Error Estimation (BEE) model in following paper. This is based on my limited understanding and I can't guarantee the implementation is bug-free.\n",
    "\n",
    "[Emmanouil Antonios Platanios, Avinava Dubey, Tom Mitchell ; Proceedings of The 33rd International Conference on Machine Learning, PMLR 48:1416-1425, 2016.](http://proceedings.mlr.press/v48/platanios16.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Generate dummy data\n",
    "\n",
    "In real-life, the estimations should come from estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_estimators = 4\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_matrix = np.random.randint(0, 2, (num_samples, num_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gibbs Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 50\n",
    "num_samples = labeling_matrix.shape[0]\n",
    "num_estimators = labeling_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial error rate: [0.01478959 0.01661954 0.19450443 0.16508176]\n"
     ]
    }
   ],
   "source": [
    "true_labels = np.random.randint(0, 2, num_samples)\n",
    "error_rates = 0.2*np.random.random(num_estimators)\n",
    "print(\"initial error rate:\", error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyper-parameters > 1 so that it's convex shape with mean 0.5. \n",
    "alpha_p, beta_p, alpha_e, beta_e = 2, 2, 2, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_p():\n",
    "    \"\"\" equation 2 + discounting the old label when sampling\n",
    "    \"\"\"\n",
    "    sigma_l = np.sum(true_labels)\n",
    "    return np.random.beta(alpha_p + sigma_l, beta_p + num_samples - sigma_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_l(p, i):\n",
    "    \"\"\" equation 3\n",
    "    \"\"\"\n",
    "    pi = 1\n",
    "    # the number of correct predictions of each estimator. dim [num_estimators, 1]\n",
    "    pi = np.zeros(2)  # the pi value for l=0 and l=1\n",
    "    for k in range(2):    \n",
    "        num_corrects = labeling_matrix[i,:] == k\n",
    "        temp = np.power(error_rates, 1 - num_corrects)*np.power(1 - error_rates, num_corrects)\n",
    "        pi[k] = np.prod(temp)\n",
    "    prob = pi * np.asarray([1-p, p])\n",
    "    positive_prob = prob[1]/np.sum(prob)\n",
    "    return random.binomial(1, positive_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_e(j):\n",
    "    \"\"\" equation 4\n",
    "    \"\"\"\n",
    "    sigma_j = np.sum(labeling_matrix[:, j] == true_labels)\n",
    "    return np.random.beta(alpha_e + sigma_j, beta_e + num_samples - sigma_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0 :\n",
      "Estimator accuracy: [0.0991644  0.14431785 0.334768   0.06524638]\n",
      "Iteration 1 :\n",
      "Estimator accuracy: [0.9595642  0.9077215  0.66613227 0.98375647]\n",
      "Iteration 2 :\n",
      "Estimator accuracy: [0.07955334 0.11209361 0.38814018 0.06319425]\n",
      "Iteration 3 :\n",
      "Estimator accuracy: [0.91937292 0.92211103 0.66620295 0.97203312]\n",
      "Iteration 4 :\n",
      "Estimator accuracy: [0.09628537 0.1230774  0.37456843 0.11796218]\n",
      "Iteration 5 :\n",
      "Estimator accuracy: [0.95378078 0.93439577 0.66027637 0.95436496]\n",
      "Iteration 6 :\n",
      "Estimator accuracy: [0.11846627 0.08854344 0.30590127 0.06125564]\n",
      "Iteration 7 :\n",
      "Estimator accuracy: [0.95153381 0.93784875 0.66264068 0.97646642]\n",
      "Iteration 8 :\n",
      "Estimator accuracy: [0.11553379 0.11559109 0.37038231 0.07592953]\n",
      "Iteration 9 :\n",
      "Estimator accuracy: [0.94002122 0.94173215 0.699374   0.95706724]\n",
      "Iteration 10 :\n",
      "Estimator accuracy: [0.09899512 0.11967651 0.42670451 0.06972055]\n",
      "Iteration 11 :\n",
      "Estimator accuracy: [0.94084482 0.92680299 0.73004305 0.98041103]\n",
      "Iteration 12 :\n",
      "Estimator accuracy: [0.08161867 0.07405087 0.31834017 0.05038443]\n",
      "Iteration 13 :\n",
      "Estimator accuracy: [0.90352015 0.95739909 0.66226731 0.97606146]\n",
      "Iteration 14 :\n",
      "Estimator accuracy: [0.1041102  0.1118797  0.42872279 0.06140065]\n",
      "Iteration 15 :\n",
      "Estimator accuracy: [0.91525992 0.93110357 0.66521502 0.96895178]\n",
      "Iteration 16 :\n",
      "Estimator accuracy: [0.08771096 0.10145696 0.34919352 0.09908665]\n",
      "Iteration 17 :\n",
      "Estimator accuracy: [0.98730252 0.92495834 0.59058702 0.96816287]\n",
      "Iteration 18 :\n",
      "Estimator accuracy: [0.07476316 0.1224494  0.39056688 0.08555164]\n",
      "Iteration 19 :\n",
      "Estimator accuracy: [0.94024388 0.90846841 0.66792734 0.97093648]\n",
      "Iteration 20 :\n",
      "Estimator accuracy: [0.06154898 0.09898861 0.42424413 0.05890902]\n",
      "Iteration 21 :\n",
      "Estimator accuracy: [0.95183451 0.93797455 0.69138027 0.98830717]\n",
      "Iteration 22 :\n",
      "Estimator accuracy: [0.13254473 0.11894206 0.33916393 0.07832318]\n",
      "Iteration 23 :\n",
      "Estimator accuracy: [0.95033478 0.90532718 0.68080789 0.95374218]\n",
      "Iteration 24 :\n",
      "Estimator accuracy: [0.0839826  0.12541356 0.31292965 0.11255972]\n",
      "Iteration 25 :\n",
      "Estimator accuracy: [0.94943353 0.92881857 0.67852306 0.98382258]\n",
      "Iteration 26 :\n",
      "Estimator accuracy: [0.13209447 0.12583004 0.32853131 0.08996356]\n",
      "Iteration 27 :\n",
      "Estimator accuracy: [0.93337775 0.93243645 0.75396017 0.94185692]\n",
      "Iteration 28 :\n",
      "Estimator accuracy: [0.12637965 0.1353874  0.35557894 0.05759994]\n",
      "Iteration 29 :\n",
      "Estimator accuracy: [0.95867653 0.94954816 0.68945026 0.95929795]\n",
      "Iteration 30 :\n",
      "Estimator accuracy: [0.08033582 0.10995028 0.39861712 0.0543317 ]\n",
      "Iteration 31 :\n",
      "Estimator accuracy: [0.94530169 0.93490164 0.70476244 0.97034492]\n",
      "Iteration 32 :\n",
      "Estimator accuracy: [0.10782678 0.10346113 0.341356   0.05642768]\n",
      "Iteration 33 :\n",
      "Estimator accuracy: [0.95065217 0.95630136 0.68681876 0.98294005]\n",
      "Iteration 34 :\n",
      "Estimator accuracy: [0.06573813 0.14862519 0.31229449 0.07347448]\n",
      "Iteration 35 :\n",
      "Estimator accuracy: [0.93824072 0.96466223 0.65312127 0.98243256]\n",
      "Iteration 36 :\n",
      "Estimator accuracy: [0.11713334 0.10701587 0.36265574 0.05092658]\n",
      "Iteration 37 :\n",
      "Estimator accuracy: [0.97513015 0.90131853 0.71302435 0.9747141 ]\n",
      "Iteration 38 :\n",
      "Estimator accuracy: [0.12759791 0.10561966 0.37582977 0.06893349]\n",
      "Iteration 39 :\n",
      "Estimator accuracy: [0.95634131 0.92878751 0.65571149 0.93449625]\n",
      "Iteration 40 :\n",
      "Estimator accuracy: [0.05154133 0.11286781 0.32777598 0.05279244]\n",
      "Iteration 41 :\n",
      "Estimator accuracy: [0.93208167 0.93715055 0.66467348 0.97868951]\n",
      "Iteration 42 :\n",
      "Estimator accuracy: [0.07402534 0.1184021  0.41545409 0.07705517]\n",
      "Iteration 43 :\n",
      "Estimator accuracy: [0.95670612 0.92309115 0.73418346 0.94895006]\n",
      "Iteration 44 :\n",
      "Estimator accuracy: [0.07502214 0.12875285 0.36454399 0.0382316 ]\n",
      "Iteration 45 :\n",
      "Estimator accuracy: [0.95115793 0.90552295 0.61024196 0.96932096]\n",
      "Iteration 46 :\n",
      "Estimator accuracy: [0.08732516 0.1001086  0.35660748 0.0614841 ]\n",
      "Iteration 47 :\n",
      "Estimator accuracy: [0.9622304  0.91773285 0.6381938  0.98240276]\n",
      "Iteration 48 :\n",
      "Estimator accuracy: [0.08641507 0.11518044 0.28094548 0.0544511 ]\n",
      "Iteration 49 :\n",
      "Estimator accuracy: [0.96195624 0.92852385 0.65163528 0.97867796]\n"
     ]
    }
   ],
   "source": [
    "for it in range(num_iters):\n",
    "    for i in range(num_samples):\n",
    "        p = sample_p()\n",
    "        true_labels[i] = sample_l(p, i)\n",
    "    for j in range(num_estimators):\n",
    "        error_rates[j] = sample_e(j)\n",
    "    print(\"Iteration\", it, \":\")\n",
    "    print(\"Estimator accuracy:\", 1 - error_rates)\n",
    "    #print(true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate some real predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33, random_state=42)\n",
    "num_samples = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative 1: varying the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples: (6, 30)\n",
      "0.8936170212765957\n",
      "num_samples: (8, 30)\n",
      "0.925531914893617\n",
      "num_samples: (22, 30)\n",
      "0.9308510638297872\n",
      "num_samples: (39, 30)\n",
      "0.9308510638297872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "train_ratios = [0.02, 0.02, 0.05, 0.1]\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(train_ratios)):\n",
    "    mask = np.random.binomial(1, train_ratios[i], num_samples)\n",
    "    #print(mask)\n",
    "    X = X_train[mask==1]\n",
    "    y = y_train[mask==1]\n",
    "    print(\"num_samples:\", X.shape)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    print(model.score(X_test, y_test))\n",
    "    predictions.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative 2: split the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples: (381, 2)\n",
      "0.9148936170212766\n",
      "num_samples: (381, 13)\n",
      "0.9202127659574468\n",
      "num_samples: (381, 2)\n",
      "0.6436170212765957\n",
      "num_samples: (381, 13)\n",
      "0.9680851063829787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "feature_ids = [0, 2, 15, 17, 30]\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(train_ratios)):\n",
    "    X = X_train[:, feature_ids[i]: feature_ids[i+1]]\n",
    "    y = y_train\n",
    "    X_test_temp = X_test[:, feature_ids[i]: feature_ids[i+1]]\n",
    "    print(\"num_samples:\", X.shape)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    print(model.score(X_test_temp, y_test))\n",
    "    predictions.append(model.predict(X_test_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 4)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.column_stack(predictions)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_matrix = predictions \n",
    "# set the variable down. Now go back to section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
