{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating Accuracy from Unlabeled Data\n",
    "\n",
    "Try to implement the Bayesian Error Estimation (BEE) model in following paper. This is based on my limited understanding and I can't guarantee the implementation is bug-free.\n",
    "\n",
    "[Emmanouil Antonios Platanios, Avinava Dubey, Tom Mitchell ; Proceedings of The 33rd International Conference on Machine Learning, PMLR 48:1416-1425, 2016.](http://proceedings.mlr.press/v48/platanios16.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Generate dummy data\n",
    "\n",
    "In real-life, the estimations should come from estimators"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_estimators = 4\n",
    "num_samples = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_matrix = np.random.randint(0, 2, (num_samples, num_estimators))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Gibbs Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_iters = 50\n",
    "num_samples = labeling_matrix.shape[0]\n",
    "num_estimators = labeling_matrix.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial error rate: [0.01478959 0.01661954 0.19450443 0.16508176]\n"
     ]
    }
   ],
   "source": [
    "true_labels = np.random.randint(0, 2, num_samples)\n",
    "error_rates = 0.2*np.random.random(num_estimators)\n",
    "print(\"initial error rate:\", error_rates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the hyper-parameters > 1 so that it's convex shape with mean 0.5. \n",
    "alpha_p, beta_p, alpha_e, beta_e = 2, 2, 2, 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_p():\n",
    "    \"\"\" equation 2 + discounting the old label when sampling\n",
    "    \"\"\"\n",
    "    sigma_l = np.sum(true_labels)\n",
    "    return np.random.beta(alpha_p + sigma_l, beta_p + num_samples - sigma_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_l(p, i):\n",
    "    \"\"\" equation 3\n",
    "    \"\"\"\n",
    "    pi = 1\n",
    "    # the number of correct predictions of each estimator. dim [num_estimators, 1]\n",
    "    pi = np.zeros(2)  # the pi value for l=0 and l=1\n",
    "    for k in range(2):    \n",
    "        num_corrects = labeling_matrix[i,:] == k\n",
    "        temp = np.power(error_rates, 1 - num_corrects)*np.power(1 - error_rates, num_corrects)\n",
    "        pi[k] = np.prod(temp)\n",
    "    prob = pi * np.asarray([1-p, p])\n",
    "    positive_prob = prob[1]/np.sum(prob)\n",
    "    return random.binomial(1, positive_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_e(j):\n",
    "    \"\"\" equation 4\n",
    "    \"\"\"\n",
    "    sigma_j = np.sum(labeling_matrix[:, j] != true_labels)\n",
    "    return np.random.beta(alpha_e + sigma_j, beta_e + num_samples - sigma_j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1 :\n",
      "Estimator accuracy: [0.9595642  0.9077215  0.66613227 0.98375647]\n",
      "Iteration 9 :\n",
      "Estimator accuracy: [0.94002122 0.94173215 0.699374   0.95706724]\n",
      "Iteration 19 :\n",
      "Estimator accuracy: [0.94024388 0.90846841 0.66792734 0.97093648]\n",
      "Iteration 29 :\n",
      "Estimator accuracy: [0.95867653 0.94954816 0.68945026 0.95929795]\n",
      "Iteration 39 :\n",
      "Estimator accuracy: [0.95634131 0.92878751 0.65571149 0.93449625]\n",
      "Iteration 49 :\n",
      "Estimator accuracy: [0.96195624 0.92852385 0.65163528 0.97867796]\n"
     ]
    }
   ],
   "source": [
    "for it in range(num_iters):\n",
    "    for i in range(num_samples):\n",
    "        p = sample_p()\n",
    "        true_labels[i] = sample_l(p, i)\n",
    "    for j in range(num_estimators):\n",
    "        error_rates[j] = sample_e(j)\n",
    "    print(\"Iteration\", it, \":\")\n",
    "    print(\"Estimator accuracy:\", 1 - error_rates)\n",
    "    #print(true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Generate some real predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.model_selection import train_test_split\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(data.data, data.target, test_size=0.33, random_state=42)\n",
    "num_samples = X_train.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative 1: varying the number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples: (6, 30)\n",
      "0.8936170212765957\n",
      "num_samples: (8, 30)\n",
      "0.925531914893617\n",
      "num_samples: (22, 30)\n",
      "0.9308510638297872\n",
      "num_samples: (39, 30)\n",
      "0.9308510638297872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "train_ratios = [0.02, 0.02, 0.05, 0.1]\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(train_ratios)):\n",
    "    mask = np.random.binomial(1, train_ratios[i], num_samples)\n",
    "    #print(mask)\n",
    "    X = X_train[mask==1]\n",
    "    y = y_train[mask==1]\n",
    "    print(\"num_samples:\", X.shape)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    print(model.score(X_test, y_test))\n",
    "    predictions.append(model.predict(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Alternative 2: split the feature space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num_samples: (381, 2)\n",
      "0.9148936170212766\n",
      "num_samples: (381, 13)\n",
      "0.9202127659574468\n",
      "num_samples: (381, 2)\n",
      "0.6436170212765957\n",
      "num_samples: (381, 13)\n",
      "0.9680851063829787\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "/Users/admin/miniconda2/envs/py3env/lib/python3.6/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "feature_ids = [0, 2, 15, 17, 30]\n",
    "\n",
    "predictions = []\n",
    "for i in range(len(train_ratios)):\n",
    "    X = X_train[:, feature_ids[i]: feature_ids[i+1]]\n",
    "    y = y_train\n",
    "    X_test_temp = X_test[:, feature_ids[i]: feature_ids[i+1]]\n",
    "    print(\"num_samples:\", X.shape)\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X, y)\n",
    "    print(model.score(X_test_temp, y_test))\n",
    "    predictions.append(model.predict(X_test_temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(188, 4)"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = np.column_stack(predictions)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeling_matrix = predictions \n",
    "# set the variable down. Now go back to section 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
